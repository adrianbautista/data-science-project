{
 "metadata": {
  "name": "",
  "signature": "sha256:999a6c2ee6d3462a38ef40e2a375a27f7eefd48ccb21250bd7e70133c290d08a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import linear_model, naive_bayes, feature_selection, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips_with_adjectives = pd.read_pickle('./dumps/tips_with_adjectives.pkl')\n",
      "adj_dummies = pd.read_pickle('./dumps/adjective_dataframe.pkl')\n",
      "adj_df = pd.read_csv('./dumps/adjective_count_list.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "desired_columns = [\n",
      "    'foursquare_id',\n",
      "    'DBA',\n",
      "    'description', \n",
      "    'tip_words', \n",
      "    'tip_adjs', \n",
      "    'adj_string', \n",
      "    'foursquare_rating',\n",
      "    'foursquare_num_of_users',\n",
      "    'foursquare_price_tier',\n",
      "    'grade_A', \n",
      "    'grade_C',\n",
      "    'GRADE',\n",
      "    'BORO', \n",
      "    'ZIPCODE'\n",
      "]\n",
      "\n",
      "tips_df = tips_with_adjectives[desired_columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjective_list = list(adj_df[adj_df['count'] > 10]['word'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_and_score(model, x_features, y_targets, columns, model_type):\n",
      "    model.fit(x_features, y_targets)\n",
      "    score = model.score(x_features, y_targets)\n",
      "    y_pred = model.predict(x_features)\n",
      "    auc = metrics.roc_auc_score(y_targets, y_pred)\n",
      "    \n",
      "    p_values = feature_selection.f_classif(x_features, y_targets)\n",
      "    \n",
      "    if model_type == 'naive-bayes' or model_type == 'logistic':\n",
      "        coef_list = [np.exp(round(x, 4)) for x in model.coef_[0]]\n",
      "    elif model_type == 'linear':\n",
      "        coef_list = [round(x, 4) for x in model.coef_]\n",
      "        \n",
      "    \n",
      "    df_dict = {'adjective': columns, 'p-value': p_values[0], 'coef': coef_list}\n",
      "    model_df = pd.DataFrame(df_dict)\n",
      "    model_df.sort(['p-value', 'coef'], ascending=[1,0], inplace=True)\n",
      "    \n",
      "    print 'MODEL: ', model\n",
      "    print 'SCORE: ', score\n",
      "    print 'AUC: ', auc\n",
      "    print '\\n'\n",
      "    \n",
      "    print 'TOP PREDICTORS (p-value < 0.05):'\n",
      "    print model_df[model_df['p-value'] <= 0.05]\n",
      "    print '\\n'\n",
      "    \n",
      "#     return model_df\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips_adj_df = tips_df.drop(['grade_A', 'grade_C', 'GRADE'], axis=1).join(adj_dummies)\n",
      "# ADJECTIVE COLUMNS START AT INDEX 11\n",
      "\n",
      "# based on adjectives included in tip descriptions\n",
      "X_adjs = tips_adj_df.ix[:, 11:]\n",
      "\n",
      "# based on ratings, number of users, and price tier\n",
      "X_foursquare_info = tips_adj_df[['foursquare_rating', 'foursquare_num_of_users', 'foursquare_price_tier']].dropna(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predicting Grade \"A\" restaurants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tips_df['grade_A']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X_adjs, y, random_state=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_multi_nb = naive_bayes.MultinomialNB()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_multi_nb, X_train, y_train, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_multi_nb, X_test, y_test, X_adjs.columns, 'naive-bayes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.905538857879\n",
        "AUC:  0.504331024334\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "32       cheese  0.014229  0.000002\n",
        "33       cheesy  0.000930  0.000017\n",
        "181       ready  0.000930  0.000017\n",
        "238      unique  0.000930  0.000017\n",
        "62        early  0.002697  0.000050\n",
        "220       super  0.006231  0.000119\n",
        "70      english  0.001348  0.001169\n",
        "151     natural  0.000511  0.002119\n",
        "167        past  0.000511  0.002119\n",
        "190     russian  0.000511  0.002119\n",
        "3     addictive  0.000465  0.002938\n",
        "86         flat  0.000465  0.002938\n",
        "83          few  0.002790  0.005415\n",
        "239       usual  0.000884  0.005881\n",
        "118  incredible  0.001441  0.006368\n",
        "135      little  0.007301  0.007746\n",
        "134       light  0.001906  0.008499\n",
        "183  reasonable  0.001906  0.008499\n",
        "143        many  0.002371  0.010634\n",
        "209       solid  0.001720  0.011782\n",
        "68     eggplant  0.001023  0.017241\n",
        "172    pleasant  0.002557  0.017704\n",
        "180       quiet  0.001488  0.018024\n",
        "244       weird  0.000558  0.018941\n",
        "250      yellow  0.000558  0.018941\n",
        "84        first  0.004278  0.019281\n",
        "215       steak  0.004696  0.022156\n",
        "233        true  0.000837  0.023425\n",
        "130       large  0.003394  0.023647\n",
        "119      indian  0.001255  0.024271\n",
        "21         blue  0.001674  0.026206\n",
        "179       quick  0.003813  0.027014\n",
        "15        basic  0.000418  0.027274\n",
        "13          bad  0.006603  0.039575\n",
        "6      american  0.001209  0.048326\n",
        "158       olive  0.000605  0.049339\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.906491499227\n",
        "AUC:  0.509549498391\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "105       great  0.064480  0.000033\n",
        "37      classic  0.001478  0.000437\n",
        "40        close  0.001478  0.000437\n",
        "122       irish  0.001478  0.000437\n",
        "209       solid  0.001478  0.000437\n",
        "85         fish  0.004164  0.001319\n",
        "95       garlic  0.003896  0.006054\n",
        "118  incredible  0.001343  0.006285\n",
        "146    mediocre  0.001343  0.006285\n",
        "180       quiet  0.001343  0.006285\n",
        "126         key  0.001612  0.012641\n",
        "107     grilled  0.005776  0.018470\n",
        "53       delish  0.004433  0.020685\n",
        "71       enough  0.004433  0.020685\n",
        "184         red  0.004433  0.020685\n",
        "113        high  0.004971  0.025336\n",
        "52    delicious  0.021494  0.032550\n",
        "227    terrible  0.002418  0.035597\n",
        "129      korean  0.001209  0.036185\n",
        "145        mean  0.001209  0.036185\n",
        "195      second  0.001209  0.036185\n",
        "66          eat  0.007389  0.045435\n",
        "150       music  0.007389  0.045435\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_linear = linear_model.LinearRegression()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_linear, X_train, y_train, X_adjs.columns, 'linear')\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_linear, X_test, y_test, X_adjs.columns, 'linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0358827563328\n",
        "AUC:  0.674930598773\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective    coef   p-value\n",
        "32       cheese -0.0020  0.000002\n",
        "33       cheesy  0.0046  0.000017\n",
        "181       ready -0.0024  0.000017\n",
        "238      unique -0.0204  0.000017\n",
        "62        early -0.0333  0.000050\n",
        "220       super  0.0018  0.000119\n",
        "70      english  0.0227  0.001169\n",
        "190     russian  0.0422  0.002119\n",
        "151     natural  0.0340  0.002119\n",
        "167        past  0.0077  0.002119\n",
        "3     addictive  0.0179  0.002938\n",
        "86         flat  0.0020  0.002938\n",
        "83          few  0.0086  0.005415\n",
        "239       usual  0.0589  0.005881\n",
        "118  incredible  0.0101  0.006368\n",
        "135      little -0.0025  0.007746\n",
        "183  reasonable  0.0442  0.008499\n",
        "134       light -0.0025  0.008499\n",
        "143        many  0.0045  0.010634\n",
        "209       solid  0.0151  0.011782\n",
        "68     eggplant  0.0175  0.017241\n",
        "172    pleasant  0.0089  0.017704\n",
        "180       quiet  0.0274  0.018024\n",
        "250      yellow  0.0359  0.018941\n",
        "244       weird  0.0243  0.018941\n",
        "84        first -0.0046  0.019281\n",
        "215       steak  0.0017  0.022156\n",
        "233        true  0.0080  0.023425\n",
        "130       large -0.0088  0.023647\n",
        "119      indian  0.0195  0.024271\n",
        "21         blue  0.0058  0.026206\n",
        "179       quick  0.0073  0.027014\n",
        "15        basic -0.0024  0.027274\n",
        "13          bad -0.0099  0.039575\n",
        "6      american -0.0138  0.048326\n",
        "158       olive  0.0904  0.049339\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0732013486333\n",
        "AUC:  0.742859959619\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective    coef   p-value\n",
        "105       great  0.0149  0.000033\n",
        "122       irish  0.0637  0.000437\n",
        "37      classic  0.0352  0.000437\n",
        "40        close  0.0328  0.000437\n",
        "209       solid  0.0301  0.000437\n",
        "85         fish  0.0204  0.001319\n",
        "95       garlic  0.0108  0.006054\n",
        "180       quiet -0.0057  0.006285\n",
        "146    mediocre -0.0148  0.006285\n",
        "118  incredible -0.0362  0.006285\n",
        "126         key -0.0449  0.012641\n",
        "107     grilled -0.0129  0.018470\n",
        "184         red  0.0112  0.020685\n",
        "53       delish -0.0128  0.020685\n",
        "71       enough -0.0315  0.020685\n",
        "113        high -0.0160  0.025336\n",
        "52    delicious  0.0025  0.032550\n",
        "227    terrible -0.0118  0.035597\n",
        "129      korean  0.0629  0.036185\n",
        "195      second -0.0069  0.036185\n",
        "145        mean -0.0221  0.036185\n",
        "66          eat  0.0428  0.045435\n",
        "150       music  0.0262  0.045435\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic = linear_model.LogisticRegression()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_logistic, X_train, y_train, X_adjs.columns, )\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_logistic, X_test, y_test, X_adjs.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.988149420352\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "    adjective      coef   p-value\n",
        "192     salad  0.856330  0.000035\n",
        "130     large  1.040811  0.002901\n",
        "41       cold  0.961847  0.004235\n",
        "34    chicken  1.063856  0.005296\n",
        "153       new  0.879238  0.009261\n",
        "157       old  1.069402  0.011163\n",
        "150     music  0.857529  0.011718\n",
        "13        bad  1.102522  0.014862\n",
        "113      high  0.957433  0.016993\n",
        "114  horrible  0.934260  0.022876\n",
        "58       dont  0.898616  0.029565\n",
        "84      first  0.941859  0.033064\n",
        "189      rude  1.086759  0.035656\n",
        "251     youll  1.098011  0.047613\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.99227202473\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "         adjective      coef   p-value\n",
        "90           fresh  0.950374  0.002677\n",
        "187       rosemary  0.994217  0.007786\n",
        "156         normal  0.987775  0.007786\n",
        "43   complimentary  0.986887  0.007786\n",
        "170     phenomenal  0.983439  0.007786\n",
        "203          sized  0.990347  0.015576\n",
        "144        massive  0.987973  0.015576\n",
        "151        natural  0.987973  0.015576\n",
        "235        typical  0.985013  0.015576\n",
        "238         unique  0.981277  0.015576\n",
        "213    spectacular  0.981179  0.015576\n",
        "78          famous  0.981081  0.015576\n",
        "87       flavorful  0.971708  0.015576\n",
        "2           actual  0.969669  0.015576\n",
        "48        creative  0.951039  0.015576\n",
        "32          cheese  1.024290  0.016684\n",
        "221       superior  0.986295  0.023371\n",
        "44       congested  0.984127  0.023371\n",
        "7            asian  0.979415  0.023371\n",
        "133          later  0.977751  0.023371\n",
        "206          smile  0.977067  0.023371\n",
        "236     unbeatable  0.976872  0.023371\n",
        "239          usual  0.976676  0.023371\n",
        "175        popular  0.975700  0.023371\n",
        "207         social  0.974238  0.023371\n",
        "30         central  0.974140  0.023371\n",
        "117         iconic  0.972097  0.023371\n",
        "201        similar  0.971611  0.023371\n",
        "15           basic  0.968603  0.023371\n",
        "152         nearby  0.957816  0.023371\n",
        "..             ...       ...       ...\n",
        "8        attentive  0.970057  0.038971\n",
        "63           earth  0.968022  0.038971\n",
        "216        stellar  0.966088  0.038971\n",
        "140          magic  0.965895  0.038971\n",
        "234        turkish  0.965123  0.038971\n",
        "250         yellow  0.963965  0.038971\n",
        "173         polish  0.963483  0.038971\n",
        "218         strong  0.962232  0.038971\n",
        "0       20500daily  0.961943  0.038971\n",
        "229           thin  0.961366  0.038971\n",
        "29          casual  0.959637  0.038971\n",
        "42     comfortable  0.958007  0.038971\n",
        "167           past  0.957528  0.038971\n",
        "28       caribbean  0.939413  0.038971\n",
        "64            east  0.936505  0.038971\n",
        "69           empty  0.959062  0.046778\n",
        "86            flat  0.958966  0.046778\n",
        "39           clear  0.958295  0.046778\n",
        "25            busy  0.957145  0.046778\n",
        "81             fat  0.955997  0.046778\n",
        "198        several  0.953134  0.046778\n",
        "61             dry  0.952562  0.046778\n",
        "98           giant  0.952276  0.046778\n",
        "148         modern  0.949899  0.046778\n",
        "217       straight  0.943650  0.046778\n",
        "16            bean  0.940635  0.046778\n",
        "57            dive  0.939037  0.046778\n",
        "228       terrific  0.938193  0.046778\n",
        "174           poor  0.932021  0.046778\n",
        "45            cool  1.467118  0.049619\n",
        "\n",
        "[77 rows x 3 columns]\n",
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "array([[-0.12036386, -0.20331962, -0.10642979, -0.16262524, -0.13566955,\n",
        "        -0.38765504, -0.2959662 ,  0.67313101, -0.30585978, -0.52684711,\n",
        "         0.31675928, -0.24304914, -0.27425093,  0.09757498,  0.27472463,\n",
        "        -0.10067053, -0.28248781,  0.64720478,  0.78109059, -0.2377445 ,\n",
        "        -0.53569073, -0.31798515,  0.22511665, -0.85220323, -0.05250415,\n",
        "        -0.26305371, -0.35603284, -0.2352234 , -0.14299186, -0.07285819,\n",
        "        -0.21341091, -0.26177563,  0.09780465, -0.22020022,  0.06191308,\n",
        "         1.14993659,  0.15102532, -0.33573125, -0.5616549 , -0.08058798,\n",
        "         0.22008843, -0.03889336, -0.10880304,  0.63739133, -0.10782768,\n",
        "        -0.31927109,  0.27798325, -0.34289835, -0.13715527, -0.40562779,\n",
        "         0.39463977, -0.20373035,  0.33140782, -0.13671467, -0.36498375,\n",
        "         1.06512444,  0.62600892, -0.23731453, -0.10688794, -0.30648525,\n",
        "        -0.33687827, -0.27266961,  0.70891864, -0.15514015,  0.43221158,\n",
        "        -0.06370193,  0.63295932, -0.19743175,  0.48908485, -0.14603809,\n",
        "        -0.29371412, -0.52333085, -0.14480042, -0.13479234,  0.09284621,\n",
        "         0.32765413, -0.46397479,  1.4177471 , -0.14790733,  0.35627366,\n",
        "        -1.05228551, -0.40394669,  0.01073648,  0.97477188, -0.05989845,\n",
        "         0.91439741, -0.12473089, -0.33490251, -0.21909512,  0.08343271,\n",
        "         0.04234789, -0.32626835,  0.27835611, -0.49071249, -0.25900729,\n",
        "        -0.56569121, -0.56353959, -0.14983516, -0.10086868, -0.23347725,\n",
        "         0.49775094, -0.26443955, -0.22065209, -0.16388798, -0.15668216,\n",
        "        -0.02659845, -0.62642581,  0.3705666 , -0.47906486, -0.50996642,\n",
        "        -0.31383721, -0.1436098 , -0.24361253, -0.04352334, -0.06797098,\n",
        "         0.51083861, -0.63172321,  1.4793963 , -0.40408655, -0.3174039 ,\n",
        "        -0.27740943, -0.23418862, -0.17499249,  1.04596268,  0.16342158,\n",
        "        -0.22653024, -0.17589861, -0.17600116,  0.29124771, -0.268382  ,\n",
        "         0.03995577, -0.65857582, -1.29252352,  0.44906498, -0.38417316,\n",
        "        -0.90459059,  0.84145544,  0.86913038,  0.29961407,  1.1219019 ,\n",
        "        -0.16835729, -0.30182252, -0.10511136, -0.42148263, -0.09125084,\n",
        "        -0.17645851,  0.4865457 , -0.52747008, -0.1212271 , -0.51529032,\n",
        "        -0.15372973, -0.12923312, -0.19906277, -0.1287319 , -0.25141446,\n",
        "         0.11397469, -0.10762138,  0.06707315, -0.14455759, -0.26451115,\n",
        "        -0.66632415, -0.15035549, -0.14809956, -0.73738559, -0.12364899,\n",
        "        -0.14066292, -0.33916834, -0.11138165, -0.37615241, -0.17284818,\n",
        "        -0.23609699, -0.39679653,  0.34979634, -0.08269747, -0.22187399,\n",
        "        -0.15549917, -0.25798748, -0.14198591, -0.10344506,  0.96834557,\n",
        "         0.23903248,  0.53402787, -0.68896835, -0.51062441,  0.94528485,\n",
        "        -0.34281255, -0.06860476, -0.12909332, -0.11466961,  0.08316954,\n",
        "         0.67799291, -0.14508264, -0.15507484, -0.22540069, -0.1685995 ,\n",
        "        -0.29641934, -0.13564372, -0.10824573, -0.04498138, -0.33138336,\n",
        "        -0.18297385, -0.08655529, -0.29871961, -0.22803591,  0.18506378,\n",
        "        -0.85676148, -0.20816964, -0.15444066, -0.24994336,  0.87920697,\n",
        "         0.63751831,  0.55316823,  0.44022435, -0.14009301, -0.23835682,\n",
        "         0.24374807, -0.1680447 , -0.21854792, -0.27414008,  1.5835025 ,\n",
        "        -0.3704031 , -0.20923302, -0.53775004, -0.48011304, -0.49215807,\n",
        "         0.69062314,  0.33498312,  0.22804128,  0.64852923, -0.17783644,\n",
        "         0.36586906, -0.51514134, -0.17360175, -0.21765916,  0.73542726,\n",
        "        -0.17325998, -0.11053646,  0.62794869,  0.5746799 , -0.18956846,\n",
        "        -0.30504958, -0.36466282, -0.2679197 , -0.11137127, -0.10005768,\n",
        "        -0.57617858,  0.69355388, -0.50095851, -0.83399347,  0.3474288 ,\n",
        "        -0.15087323,  0.09350261, -0.24001225, -0.83198448, -0.57261402]])"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predicting Grade \"C\" restaurants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tips_df['grade_C']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X_adjs, y, random_state=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_multi_nb = naive_bayes.MultinomialNB()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_multi_nb, X_train, y_train, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_multi_nb, X_test, y_test, X_adjs.columns, 'naive-bayes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.987891799055\n",
        "AUC:  0.510608854346\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "    adjective      coef   p-value\n",
        "192     salad  0.007576  0.000035\n",
        "130     large  0.003788  0.002901\n",
        "41       cold  0.003788  0.004235\n",
        "34    chicken  0.024622  0.005296\n",
        "153       new  0.013257  0.009261\n",
        "157       old  0.003788  0.011163\n",
        "150     music  0.005682  0.011718\n",
        "13        bad  0.005682  0.014862\n",
        "113      high  0.003788  0.016993\n",
        "114  horrible  0.003788  0.022876\n",
        "58       dont  0.013257  0.029565\n",
        "84      first  0.003788  0.033064\n",
        "189      rude  0.003788  0.035656\n",
        "251     youll  0.003788  0.047613\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.99227202473\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "         adjective      coef   p-value\n",
        "90           fresh  0.006230  0.002677\n",
        "43   complimentary  0.003115  0.007786\n",
        "156         normal  0.003115  0.007786\n",
        "170     phenomenal  0.003115  0.007786\n",
        "187       rosemary  0.003115  0.007786\n",
        "2           actual  0.003115  0.015576\n",
        "48        creative  0.003115  0.015576\n",
        "78          famous  0.003115  0.015576\n",
        "87       flavorful  0.003115  0.015576\n",
        "144        massive  0.003115  0.015576\n",
        "151        natural  0.003115  0.015576\n",
        "203          sized  0.003115  0.015576\n",
        "213    spectacular  0.003115  0.015576\n",
        "235        typical  0.003115  0.015576\n",
        "238         unique  0.003115  0.015576\n",
        "32          cheese  0.006230  0.016684\n",
        "7            asian  0.003115  0.023371\n",
        "15           basic  0.003115  0.023371\n",
        "30         central  0.003115  0.023371\n",
        "44       congested  0.003115  0.023371\n",
        "117         iconic  0.003115  0.023371\n",
        "133          later  0.003115  0.023371\n",
        "152         nearby  0.003115  0.023371\n",
        "175        popular  0.003115  0.023371\n",
        "201        similar  0.003115  0.023371\n",
        "206          smile  0.003115  0.023371\n",
        "207         social  0.003115  0.023371\n",
        "221       superior  0.003115  0.023371\n",
        "236     unbeatable  0.003115  0.023371\n",
        "239          usual  0.003115  0.023371\n",
        "..             ...       ...       ...\n",
        "28       caribbean  0.003115  0.038971\n",
        "29          casual  0.003115  0.038971\n",
        "42     comfortable  0.003115  0.038971\n",
        "63           earth  0.003115  0.038971\n",
        "64            east  0.003115  0.038971\n",
        "140          magic  0.003115  0.038971\n",
        "167           past  0.003115  0.038971\n",
        "173         polish  0.003115  0.038971\n",
        "190        russian  0.003115  0.038971\n",
        "211        spanish  0.003115  0.038971\n",
        "216        stellar  0.003115  0.038971\n",
        "218         strong  0.003115  0.038971\n",
        "229           thin  0.003115  0.038971\n",
        "234        turkish  0.003115  0.038971\n",
        "250         yellow  0.003115  0.038971\n",
        "16            bean  0.003115  0.046778\n",
        "25            busy  0.003115  0.046778\n",
        "39           clear  0.003115  0.046778\n",
        "57            dive  0.003115  0.046778\n",
        "61             dry  0.003115  0.046778\n",
        "69           empty  0.003115  0.046778\n",
        "81             fat  0.003115  0.046778\n",
        "86            flat  0.003115  0.046778\n",
        "98           giant  0.003115  0.046778\n",
        "148         modern  0.003115  0.046778\n",
        "174           poor  0.003115  0.046778\n",
        "198        several  0.003115  0.046778\n",
        "217       straight  0.003115  0.046778\n",
        "228       terrific  0.003115  0.046778\n",
        "45            cool  0.006230  0.049619\n",
        "\n",
        "[77 rows x 3 columns]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_linear = linear_model.LinearRegression()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_linear, X_train, y_train, X_adjs.columns)\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_linear, X_test, y_test, X_adjs.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'numpy.float64' object is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-107-f1e6f7a4c5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Using training set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_adjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Using testing set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-91-8b24ff7e9de7>\u001b[0m in \u001b[0;36mfit_and_score\u001b[0;34m(model, x_features, y_targets, columns)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mp_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'adjective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p-value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coef'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p-value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic = linear_model.LogisticRegression()\n",
      "\n",
      "print 'Using training set'\n",
      "fit_and_score(clf_logistic, X_train, y_train, X_adjs.columns)\n",
      "\n",
      "print 'Using testing set'\n",
      "fit_and_score(clf_logistic, X_test, y_test, X_adjs.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.988149420352\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "    adjective      coef   p-value\n",
        "192     salad  0.856330  0.000035\n",
        "130     large  1.040811  0.002901\n",
        "41       cold  0.961847  0.004235\n",
        "34    chicken  1.063856  0.005296\n",
        "153       new  0.879238  0.009261\n",
        "157       old  1.069402  0.011163\n",
        "150     music  0.857529  0.011718\n",
        "13        bad  1.102522  0.014862\n",
        "113      high  0.957433  0.016993\n",
        "114  horrible  0.934260  0.022876\n",
        "58       dont  0.898616  0.029565\n",
        "84      first  0.941859  0.033064\n",
        "189      rude  1.086759  0.035656\n",
        "251     youll  1.098011  0.047613\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.99227202473\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "         adjective      coef   p-value\n",
        "90           fresh  0.950374  0.002677\n",
        "187       rosemary  0.994217  0.007786\n",
        "156         normal  0.987775  0.007786\n",
        "43   complimentary  0.986887  0.007786\n",
        "170     phenomenal  0.983439  0.007786\n",
        "203          sized  0.990347  0.015576\n",
        "144        massive  0.987973  0.015576\n",
        "151        natural  0.987973  0.015576\n",
        "235        typical  0.985013  0.015576\n",
        "238         unique  0.981277  0.015576\n",
        "213    spectacular  0.981179  0.015576\n",
        "78          famous  0.981081  0.015576\n",
        "87       flavorful  0.971708  0.015576\n",
        "2           actual  0.969669  0.015576\n",
        "48        creative  0.951039  0.015576\n",
        "32          cheese  1.024290  0.016684\n",
        "221       superior  0.986295  0.023371\n",
        "44       congested  0.984127  0.023371\n",
        "7            asian  0.979415  0.023371\n",
        "133          later  0.977751  0.023371\n",
        "206          smile  0.977067  0.023371\n",
        "236     unbeatable  0.976872  0.023371\n",
        "239          usual  0.976676  0.023371\n",
        "175        popular  0.975700  0.023371\n",
        "207         social  0.974238  0.023371\n",
        "30         central  0.974140  0.023371\n",
        "117         iconic  0.972097  0.023371\n",
        "201        similar  0.971611  0.023371\n",
        "15           basic  0.968603  0.023371\n",
        "152         nearby  0.957816  0.023371\n",
        "..             ...       ...       ...\n",
        "8        attentive  0.970057  0.038971\n",
        "63           earth  0.968022  0.038971\n",
        "216        stellar  0.966088  0.038971\n",
        "140          magic  0.965895  0.038971\n",
        "234        turkish  0.965123  0.038971\n",
        "250         yellow  0.963965  0.038971\n",
        "173         polish  0.963483  0.038971\n",
        "218         strong  0.962232  0.038971\n",
        "0       20500daily  0.961943  0.038971\n",
        "229           thin  0.961366  0.038971\n",
        "29          casual  0.959637  0.038971\n",
        "42     comfortable  0.958007  0.038971\n",
        "167           past  0.957528  0.038971\n",
        "28       caribbean  0.939413  0.038971\n",
        "64            east  0.936505  0.038971\n",
        "69           empty  0.959062  0.046778\n",
        "86            flat  0.958966  0.046778\n",
        "39           clear  0.958295  0.046778\n",
        "25            busy  0.957145  0.046778\n",
        "81             fat  0.955997  0.046778\n",
        "198        several  0.953134  0.046778\n",
        "61             dry  0.952562  0.046778\n",
        "98           giant  0.952276  0.046778\n",
        "148         modern  0.949899  0.046778\n",
        "217       straight  0.943650  0.046778\n",
        "16            bean  0.940635  0.046778\n",
        "57            dive  0.939037  0.046778\n",
        "228       terrific  0.938193  0.046778\n",
        "174           poor  0.932021  0.046778\n",
        "45            cool  1.467118  0.049619\n",
        "\n",
        "[77 rows x 3 columns]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}