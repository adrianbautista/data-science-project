{
 "metadata": {
  "name": "",
  "signature": "sha256:7758da6573cd2bd76523bd129a8fe536e87abca2882c1e5509b0a76926122db1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import folium as fm\n",
      "import geopy\n",
      "\n",
      "from sklearn import linear_model, naive_bayes, feature_selection, metrics, tree\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips_with_adjectives_1 = pd.read_pickle('./dumps/tips_with_adjectives.pkl')\n",
      "adj_dummies = pd.read_pickle('./dumps/adjective_dataframe.pkl')\n",
      "adj_df = pd.read_csv('./dumps/adjective_count_list.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(adj_dummies)\n",
      "print len(tips_with_adjectives_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15527\n",
        "15527\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjective_list = list(adj_df[adj_df['count'] > 10]['word'])\n",
      "\n",
      "print \"Number of tips: \", len(tips_with_adjectives_1)\n",
      "print \"Number of adjectives: \", len(adj_df)\n",
      "print \"Number of significant adjectives (appears in more than 10 tips): \", len(adjective_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of tips:  15527\n",
        "Number of adjectives:  1838\n",
        "Number of significant adjectives (appears in more than 10 tips):  255\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tips_with_adjectives['address'] = tips_with_adjectives.apply(lambda x: \"{0} {1} {2}, {3}, New York, NY\".format(x['BUILDING'].strip(), x['STREET'].strip(), int(x['ZIPCODE']), x['BORO']), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latlong_df = pd.read_pickle('./dumps/with_lat_long.pkl')[['foursquare_id', 'lat_long']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips_adj_df = tips_with_adjectives_1.join(adj_dummies)\n",
      "tips_adj_df.drop_duplicates(['foursquare_id', 'description'], inplace=True)\n",
      "tips_adj_df = tips_adj_df.merge(latlong_df, on='foursquare_id', how='left')\n",
      "tips_adj_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>foursquare_id</th>\n",
        "      <th>description</th>\n",
        "      <th>created_at</th>\n",
        "      <th>DBA</th>\n",
        "      <th>BORO</th>\n",
        "      <th>BUILDING</th>\n",
        "      <th>STREET</th>\n",
        "      <th>ZIPCODE</th>\n",
        "      <th>PHONE</th>\n",
        "      <th>CUISINE DESCRIPTION</th>\n",
        "      <th>...</th>\n",
        "      <th>whole</th>\n",
        "      <th>wonderful</th>\n",
        "      <th>worth</th>\n",
        "      <th>wrong</th>\n",
        "      <th>yellow</th>\n",
        "      <th>youll</th>\n",
        "      <th>young</th>\n",
        "      <th>yous</th>\n",
        "      <th>yummy</th>\n",
        "      <th>lat_long</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 4e823597775b368bbbffb549</td>\n",
        "      <td> the breakfast here is good the staff needs som...</td>\n",
        "      <td> 1359463129</td>\n",
        "      <td>                        WENDY'S</td>\n",
        "      <td>  BROOKLYN</td>\n",
        "      <td>        469</td>\n",
        "      <td>                                   FLATBUSH AVENUE</td>\n",
        "      <td> 11225</td>\n",
        "      <td> 7182875005</td>\n",
        "      <td>   Hamburgers</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> (40.6630011878, -73.9618386697)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4a7ef04bf964a52055f21fe3</td>\n",
        "      <td> eat brunch here for very reasonably priced del...</td>\n",
        "      <td> 1312045610</td>\n",
        "      <td> DJ REYNOLDS PUB AND RESTAURANT</td>\n",
        "      <td> MANHATTAN</td>\n",
        "      <td> 351       </td>\n",
        "      <td> WEST   57 STREET                              ...</td>\n",
        "      <td> 10019</td>\n",
        "      <td> 2122452912</td>\n",
        "      <td>        Irish</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  (40.7676882095, -73.985037451)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4ac68680f964a520d8b420e3</td>\n",
        "      <td> provided my wife and i with the best wedding e...</td>\n",
        "      <td> 1351084714</td>\n",
        "      <td>                RIVIERA CATERER</td>\n",
        "      <td>  BROOKLYN</td>\n",
        "      <td>       2780</td>\n",
        "      <td>                                  STILLWELL AVENUE</td>\n",
        "      <td> 11224</td>\n",
        "      <td> 7183723031</td>\n",
        "      <td>    American </td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> (40.5796712021, -73.9822941487)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4c12d4b882a3c9b6ac7bfaf8</td>\n",
        "      <td>                           when u sleep dont sleep</td>\n",
        "      <td> 1306075709</td>\n",
        "      <td>        BRUNOS ON THE BOULEVARD</td>\n",
        "      <td>    QUEENS</td>\n",
        "      <td> 8825      </td>\n",
        "      <td> ASTORIA BOULEVARD                             ...</td>\n",
        "      <td> 11369</td>\n",
        "      <td> 7183350505</td>\n",
        "      <td>    American </td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> (40.7641288111, -73.8808250427)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4bdc87a7afe8c9b645dc4f85</td>\n",
        "      <td> get the corn chowder over every other soup awe...</td>\n",
        "      <td> 1327798534</td>\n",
        "      <td>             WILKEN'S FINE FOOD</td>\n",
        "      <td>  BROOKLYN</td>\n",
        "      <td> 7114      </td>\n",
        "      <td>                  AVENUE U                        </td>\n",
        "      <td> 11234</td>\n",
        "      <td> 7184443838</td>\n",
        "      <td> Delicatessen</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> (40.6200724816, -73.9068323117)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 290 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 168,
       "text": [
        "              foursquare_id  \\\n",
        "0  4e823597775b368bbbffb549   \n",
        "1  4a7ef04bf964a52055f21fe3   \n",
        "2  4ac68680f964a520d8b420e3   \n",
        "3  4c12d4b882a3c9b6ac7bfaf8   \n",
        "4  4bdc87a7afe8c9b645dc4f85   \n",
        "\n",
        "                                         description  created_at  \\\n",
        "0  the breakfast here is good the staff needs som...  1359463129   \n",
        "1  eat brunch here for very reasonably priced del...  1312045610   \n",
        "2  provided my wife and i with the best wedding e...  1351084714   \n",
        "3                            when u sleep dont sleep  1306075709   \n",
        "4  get the corn chowder over every other soup awe...  1327798534   \n",
        "\n",
        "                              DBA       BORO    BUILDING  \\\n",
        "0                         WENDY'S   BROOKLYN         469   \n",
        "1  DJ REYNOLDS PUB AND RESTAURANT  MANHATTAN  351          \n",
        "2                 RIVIERA CATERER   BROOKLYN        2780   \n",
        "3         BRUNOS ON THE BOULEVARD     QUEENS  8825         \n",
        "4              WILKEN'S FINE FOOD   BROOKLYN  7114         \n",
        "\n",
        "                                              STREET  ZIPCODE       PHONE  \\\n",
        "0                                    FLATBUSH AVENUE    11225  7182875005   \n",
        "1  WEST   57 STREET                              ...    10019  2122452912   \n",
        "2                                   STILLWELL AVENUE    11224  7183723031   \n",
        "3  ASTORIA BOULEVARD                             ...    11369  7183350505   \n",
        "4                   AVENUE U                            11234  7184443838   \n",
        "\n",
        "  CUISINE DESCRIPTION         ...         whole wonderful worth wrong yellow  \\\n",
        "0          Hamburgers         ...             0         0     0     0      0   \n",
        "1               Irish         ...             0         0     0     0      0   \n",
        "2           American          ...             0         0     0     0      0   \n",
        "3           American          ...             0         0     0     0      0   \n",
        "4        Delicatessen         ...             0         0     0     0      0   \n",
        "\n",
        "   youll young yous yummy                         lat_long  \n",
        "0      0     0    0     0  (40.6630011878, -73.9618386697)  \n",
        "1      0     0    0     0   (40.7676882095, -73.985037451)  \n",
        "2      0     0    0     0  (40.5796712021, -73.9822941487)  \n",
        "3      0     0    0     0  (40.7641288111, -73.8808250427)  \n",
        "4      0     0    0     0  (40.6200724816, -73.9068323117)  \n",
        "\n",
        "[5 rows x 290 columns]"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# desired_columns = [\n",
      "#     'foursquare_id',\n",
      "#     'DBA',\n",
      "#     'description', \n",
      "#     'tip_words', \n",
      "#     'tip_adjs', \n",
      "#     'adj_string', \n",
      "#     'foursquare_rating',\n",
      "#     'foursquare_num_of_users',\n",
      "#     'foursquare_price_tier',\n",
      "#     'grade_A', \n",
      "#     'grade_C',\n",
      "#     'GRADE',\n",
      "#     'lat_long'\n",
      "# ]\n",
      "\n",
      "# tips_df = tips_with_adjectives[desired_columns]\n",
      "# len(tips_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def score_and_predict(model, x_features, y_targets, columns, model_type):\n",
      "    score = model.score(x_features, y_targets)\n",
      "    y_pred = model.predict(x_features)\n",
      "    auc = metrics.roc_auc_score(y_targets, y_pred)\n",
      "    \n",
      "    p_values = feature_selection.f_classif(x_features, y_targets)\n",
      "    \n",
      "    if model_type == 'naive-bayes' or model_type == 'logistic':\n",
      "        coef_list = [np.exp(round(x, 4)) for x in model.coef_[0]]\n",
      "    elif model_type == 'linear':\n",
      "        coef_list = [round(x, 4) for x in model.coef_]\n",
      "        \n",
      "    \n",
      "    df_dict = {'adjective': columns, 'p-value': p_values[0], 'coef': coef_list}\n",
      "    model_df = pd.DataFrame(df_dict)\n",
      "    model_df.sort(['p-value', 'coef'], ascending=[1,0], inplace=True)\n",
      "    \n",
      "    print 'MODEL: ', model\n",
      "    print 'SCORE: ', score\n",
      "    print 'AUC: ', auc\n",
      "    print '\\n'\n",
      "    \n",
      "    print 'TOP PREDICTORS (p-value < 0.05):'\n",
      "    print model_df[model_df['p-value'] <= 0.05]\n",
      "    print '\\n'\n",
      "    \n",
      "    #  return model_df\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for index, column in enumerate(tips_adj_df.columns.values):\n",
      "    print column, index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "foursquare_id 0\n",
        "description 1\n",
        "created_at 2\n",
        "DBA 3\n",
        "BORO 4\n",
        "BUILDING 5\n",
        "STREET 6\n",
        "ZIPCODE 7\n",
        "PHONE 8\n",
        "CUISINE DESCRIPTION 9\n",
        "INSPECTION DATE 10\n",
        "ACTION 11\n",
        "VIOLATION CODE 12\n",
        "VIOLATION DESCRIPTION 13\n",
        "CRITICAL FLAG 14\n",
        "SCORE 15\n",
        "GRADE 16\n",
        "GRADE DATE 17\n",
        "RECORD DATE 18\n",
        "INSPECTION TYPE 19\n",
        "foursquare_name 20\n",
        "foursquare_rating 21\n",
        "foursquare_category 22\n",
        "foursquare_num_of_users 23\n",
        "foursquare_price_tier 24\n",
        "grade_A 25\n",
        "grade_B 26\n",
        "grade_C 27\n",
        "grade_Not Yet Graded 28\n",
        "grade_Z 29\n",
        "tip_words 30\n",
        "tip_adjs 31\n",
        "adjective_count 32\n",
        "adj_string 33\n",
        "20500daily 34\n",
        "accept 35\n",
        "actual 36\n",
        "addictive 37\n",
        "adventurous 38\n",
        "affordable 39\n",
        "american 40\n",
        "asian 41\n",
        "attentive 42\n",
        "authentic 43\n",
        "available 44\n",
        "average 45\n",
        "awful 46\n",
        "bad 47\n",
        "baked 48\n",
        "basic 49\n",
        "bean 50\n",
        "beat 51\n",
        "beautiful 52\n",
        "big 53\n",
        "black 54\n",
        "blue 55\n",
        "breakfast 56\n",
        "bubble 57\n",
        "bushy 58\n",
        "busy 59\n",
        "cant 60\n",
        "careful 61\n",
        "caribbean 62\n",
        "casual 63\n",
        "central 64\n",
        "certain 65\n",
        "cheese 66\n",
        "cheesy 67\n",
        "chicken 68\n",
        "chinese 69\n",
        "chocolate 70\n",
        "classic 71\n",
        "clean 72\n",
        "clear 73\n",
        "close 74\n",
        "cold 75\n",
        "comfortable 76\n",
        "complimentary 77\n",
        "congested 78\n",
        "cool 79\n",
        "cozy 80\n",
        "crazy 81\n",
        "creative 82\n",
        "cute 83\n",
        "daily 84\n",
        "decent 85\n",
        "delicious 86\n",
        "delish 87\n",
        "different 88\n",
        "dirty 89\n",
        "dish 90\n",
        "dive 91\n",
        "dont 92\n",
        "double 93\n",
        "drive 94\n",
        "dry 95\n",
        "early 96\n",
        "earth 97\n",
        "east 98\n",
        "easy 99\n",
        "eat 100\n",
        "efficient 101\n",
        "eggplant 102\n",
        "empty 103\n",
        "english 104\n",
        "enough 105\n",
        "entire 106\n",
        "epic 107\n",
        "excellent 108\n",
        "expensive 109\n",
        "extra 110\n",
        "fabulous 111\n",
        "famous 112\n",
        "fantastic 113\n",
        "fast 114\n",
        "fat 115\n",
        "favorite 116\n",
        "few 117\n",
        "first 118\n",
        "fish 119\n",
        "flat 120\n",
        "flavorful 121\n",
        "free 122\n",
        "french 123\n",
        "fresh 124\n",
        "fried 125\n",
        "friendly 126\n",
        "full 127\n",
        "funny 128\n",
        "garlic 129\n",
        "general 130\n",
        "generous 131\n",
        "giant 132\n",
        "ginormous 133\n",
        "give 134\n",
        "goat 135\n",
        "good 136\n",
        "gorgeous 137\n",
        "greasy 138\n",
        "great 139\n",
        "green 140\n",
        "grilled 141\n",
        "happy 142\n",
        "hard 143\n",
        "healthy 144\n",
        "heavy 145\n",
        "helpful 146\n",
        "high 147\n",
        "horrible 148\n",
        "hot 149\n",
        "huge 150\n",
        "iconic 151\n",
        "incredible 152\n",
        "indian 153\n",
        "inexpensive 154\n",
        "interesting 155\n",
        "irish 156\n",
        "italian 157\n",
        "ive 158\n",
        "japanese 159\n",
        "key 160\n",
        "kid 161\n",
        "kind 162\n",
        "korean 163\n",
        "large 164\n",
        "last 165\n",
        "late 166\n",
        "later 167\n",
        "light 168\n",
        "little 169\n",
        "live 170\n",
        "local 171\n",
        "long 172\n",
        "low 173\n",
        "magic 174\n",
        "main 175\n",
        "major 176\n",
        "many 177\n",
        "massive 178\n",
        "mean 179\n",
        "mediocre 180\n",
        "mexican 181\n",
        "modern 182\n",
        "much 183\n",
        "music 184\n",
        "natural 185\n",
        "nearby 186\n",
        "new 187\n",
        "next 188\n",
        "nice 189\n",
        "normal 190\n",
        "old 191\n",
        "olive 192\n",
        "only 193\n",
        "open 194\n",
        "organic 195\n",
        "original 196\n",
        "other 197\n",
        "outstanding 198\n",
        "overall 199\n",
        "own 200\n",
        "past 201\n",
        "perfect 202\n",
        "personal 203\n",
        "phenomenal 204\n",
        "pic 205\n",
        "pleasant 206\n",
        "polish 207\n",
        "poor 208\n",
        "popular 209\n",
        "priceless 210\n",
        "private 211\n",
        "public 212\n",
        "quick 213\n",
        "quiet 214\n",
        "ready 215\n",
        "real 216\n",
        "reasonable 217\n",
        "red 218\n",
        "regular 219\n",
        "ridiculous 220\n",
        "rosemary 221\n",
        "royal 222\n",
        "rude 223\n",
        "russian 224\n",
        "sad 225\n",
        "salad 226\n",
        "saltfish 227\n",
        "same 228\n",
        "second 229\n",
        "separate 230\n",
        "serious 231\n",
        "several 232\n",
        "short 233\n",
        "sicilian 234\n",
        "similar 235\n",
        "simple 236\n",
        "sized 237\n",
        "slow 238\n",
        "small 239\n",
        "smile 240\n",
        "social 241\n",
        "soft 242\n",
        "solid 243\n",
        "spacious 244\n",
        "spanish 245\n",
        "special 246\n",
        "spectacular 247\n",
        "standard 248\n",
        "steak 249\n",
        "stellar 250\n",
        "straight 251\n",
        "strong 252\n",
        "such 253\n",
        "super 254\n",
        "superior 255\n",
        "sure 256\n",
        "sweet 257\n",
        "swiss 258\n",
        "table 259\n",
        "tasty 260\n",
        "terrible 261\n",
        "terrific 262\n",
        "thin 263\n",
        "tiny 264\n",
        "top 265\n",
        "traditional 266\n",
        "true 267\n",
        "turkish 268\n",
        "typical 269\n",
        "unbeatable 270\n",
        "unbelievable 271\n",
        "unique 272\n",
        "usual 273\n",
        "vegetable 274\n",
        "vegetarian 275\n",
        "want 276\n",
        "weak 277\n",
        "weird 278\n",
        "white 279\n",
        "whole 280\n",
        "wonderful 281\n",
        "worth 282\n",
        "wrong 283\n",
        "yellow 284\n",
        "youll 285\n",
        "young 286\n",
        "yous 287\n",
        "yummy 288\n",
        "lat_long 289\n"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ADJECTIVE COLUMNS ARE 31 till second to last column\n",
      "# based on adjectives included in tip descriptions\n",
      "X_adjs = tips_adj_df.ix[:, 34:-1]\n",
      "\n",
      "# based on ratings, number of users, and price tier\n",
      "X_foursquare_info = tips_adj_df[['foursquare_rating', 'foursquare_num_of_users', 'foursquare_price_tier']].dropna(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predicting Grade \"A\" restaurants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tips_adj_df['grade_A']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X_adjs, y, random_state=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_multi_nb = naive_bayes.MultinomialNB()\n",
      "clf_multi_nb = clf_multi_nb.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_multi_nb, X_train, y_train, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_multi_nb, X_test, y_test, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_multi_nb, X_adjs.values, y.values, X_adjs.columns, 'naive-bayes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.901251393879\n",
        "AUC:  0.502431233668\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective      coef   p-value\n",
        "163         other  0.005634  0.000050\n",
        "26           cant  0.009299  0.000081\n",
        "73           epic  0.000679  0.000087\n",
        "210      spacious  0.000679  0.000087\n",
        "250        yellow  0.000679  0.000087\n",
        "87      flavorful  0.001290  0.000174\n",
        "5      affordable  0.001901  0.000261\n",
        "96        general  0.002579  0.001122\n",
        "209         solid  0.001968  0.001918\n",
        "122         irish  0.001358  0.003553\n",
        "215         steak  0.006109  0.004008\n",
        "95         garlic  0.004277  0.004226\n",
        "46           cozy  0.001833  0.006104\n",
        "115           hot  0.012015  0.006348\n",
        "227      terrible  0.002647  0.007124\n",
        "158         olive  0.000747  0.008315\n",
        "237  unbelievable  0.000747  0.008315\n",
        "38          clean  0.004548  0.008604\n",
        "138          long  0.005430  0.009899\n",
        "84          first  0.004209  0.011209\n",
        "56           dish  0.002987  0.013767\n",
        "140         magic  0.000611  0.014504\n",
        "151       natural  0.000611  0.014504\n",
        "191           sad  0.000611  0.014504\n",
        "216       stellar  0.000611  0.014504\n",
        "119        indian  0.001765  0.020247\n",
        "157           old  0.004005  0.020831\n",
        "223         sweet  0.007738  0.023556\n",
        "118    incredible  0.002104  0.025013\n",
        "169      personal  0.001154  0.029040\n",
        "170    phenomenal  0.001154  0.029040\n",
        "228      terrific  0.001154  0.029040\n",
        "107       grilled  0.005974  0.031371\n",
        "81            fat  0.000815  0.033534\n",
        "127           kid  0.000815  0.033534\n",
        "162      original  0.000815  0.033534\n",
        "178        public  0.000815  0.033534\n",
        "239         usual  0.000815  0.033534\n",
        "54      different  0.002308  0.033618\n",
        "82       favorite  0.006652  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.888888888889\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "83           few  0.003665  0.000000\n",
        "56          dish  0.002987  0.000000\n",
        "14         baked  0.002715  0.000000\n",
        "93          full  0.002579  0.000000\n",
        "120  inexpensive  0.001290  0.000000\n",
        "35       chinese  0.006517  0.002318\n",
        "179        quick  0.003462  0.004851\n",
        "130        large  0.003937  0.006621\n",
        "114     horrible  0.003326  0.006621\n",
        "154         next  0.003326  0.006621\n",
        "124          ive  0.008349  0.009112\n",
        "113         high  0.002715  0.012537\n",
        "118   incredible  0.002104  0.012537\n",
        "68      eggplant  0.001833  0.012537\n",
        "146     mediocre  0.001222  0.012537\n",
        "149         much  0.008077  0.014883\n",
        "10     available  0.002104  0.015660\n",
        "47         crazy  0.001968  0.015660\n",
        "199        short  0.001901  0.015660\n",
        "25          busy  0.001629  0.015660\n",
        "104       greasy  0.001154  0.015660\n",
        "133        later  0.001154  0.015660\n",
        "163        other  0.005634  0.020173\n",
        "116         huge  0.004141  0.025169\n",
        "254        yummy  0.006992  0.040728\n",
        "131         last  0.002579  0.045608\n",
        "54     different  0.002308  0.045608\n",
        "23        bubble  0.002240  0.045608\n",
        "5     affordable  0.001901  0.045608\n",
        "51        decent  0.005023  0.049499\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.898160193273\n",
        "AUC:  0.50176809245\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "230        tiny  0.001968  0.000085\n",
        "151     natural  0.000611  0.000490\n",
        "3     addictive  0.000543  0.000490\n",
        "228    terrific  0.001154  0.000981\n",
        "238      unique  0.001086  0.000981\n",
        "169    personal  0.001154  0.002052\n",
        "54    different  0.002308  0.002205\n",
        "163       other  0.005634  0.002261\n",
        "90        fresh  0.014595  0.002581\n",
        "13          bad  0.008077  0.003905\n",
        "66          eat  0.009299  0.007615\n",
        "29       casual  0.000407  0.007943\n",
        "224       swiss  0.000407  0.007943\n",
        "9     authentic  0.003190  0.008253\n",
        "180       quiet  0.001968  0.009322\n",
        "5    affordable  0.001901  0.009322\n",
        "40        close  0.001901  0.009322\n",
        "58         dont  0.025929  0.009461\n",
        "182        real  0.003734  0.010006\n",
        "95       garlic  0.004277  0.010360\n",
        "1        accept  0.001154  0.010862\n",
        "30      central  0.001154  0.010862\n",
        "56         dish  0.002987  0.011253\n",
        "140       magic  0.000611  0.015087\n",
        "191         sad  0.000611  0.015087\n",
        "204        slow  0.007195  0.016624\n",
        "157         old  0.004005  0.018804\n",
        "79    fantastic  0.004887  0.020690\n",
        "38        clean  0.004548  0.023304\n",
        "119      indian  0.001765  0.024510\n",
        "202      simple  0.001697  0.024510\n",
        "20        black  0.002851  0.029148\n",
        "57         dive  0.001018  0.030205\n",
        "143        many  0.003055  0.032713\n",
        "130       large  0.003937  0.036375\n",
        "251       youll  0.003937  0.036375\n",
        "26         cant  0.009299  0.037648\n",
        "118  incredible  0.002104  0.038944\n",
        "110     healthy  0.002308  0.039847\n",
        "209       solid  0.001968  0.039847\n",
        "45         cool  0.004277  0.043770\n",
        "234     turkish  0.000815  0.044770\n",
        "193    saltfish  0.000475  0.045706\n",
        "178      public  0.000815  0.046227\n",
        "210    spacious  0.000679  0.046227\n",
        "15        basic  0.000475  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_linear = linear_model.LinearRegression()\n",
      "clf_linear = clf_linear.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_linear, X_train, y_train, X_adjs.columns, 'linear')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_linear, X_test, y_test, X_adjs.columns, 'linear')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_linear, X_adjs.values, y.values, X_adjs.columns, 'linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0306220058522\n",
        "AUC:  0.65453453789\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective    coef   p-value\n",
        "163         other -0.0005  0.000050\n",
        "26           cant  0.0110  0.000081\n",
        "73           epic  0.0196  0.000087\n",
        "250        yellow  0.0143  0.000087\n",
        "210      spacious  0.0123  0.000087\n",
        "87      flavorful  0.0218  0.000174\n",
        "5      affordable  0.0061  0.000261\n",
        "96        general  0.0292  0.001122\n",
        "209         solid  0.0167  0.001918\n",
        "122         irish -0.0082  0.003553\n",
        "215         steak -0.0008  0.004008\n",
        "95         garlic -0.0077  0.004226\n",
        "46           cozy -0.0200  0.006104\n",
        "115           hot  0.0042  0.006348\n",
        "227      terrible -0.0021  0.007124\n",
        "158         olive  0.0464  0.008315\n",
        "237  unbelievable  0.0079  0.008315\n",
        "38          clean  0.0037  0.008604\n",
        "138          long -0.0036  0.009899\n",
        "84          first -0.0020  0.011209\n",
        "56           dish  0.0091  0.013767\n",
        "151       natural  0.0361  0.014504\n",
        "191           sad  0.0085  0.014504\n",
        "216       stellar -0.0123  0.014504\n",
        "140         magic -0.0354  0.014504\n",
        "119        indian -0.0069  0.020247\n",
        "157           old -0.0030  0.020831\n",
        "223         sweet  0.0028  0.023556\n",
        "118    incredible  0.0127  0.025013\n",
        "228      terrific  0.0222  0.029040\n",
        "169      personal -0.0176  0.029040\n",
        "170    phenomenal -0.0186  0.029040\n",
        "107       grilled  0.0041  0.031371\n",
        "239         usual  0.0336  0.033534\n",
        "127           kid  0.0176  0.033534\n",
        "162      original  0.0168  0.033534\n",
        "81            fat  0.0163  0.033534\n",
        "178        public  0.0145  0.033534\n",
        "54      different -0.0040  0.033618\n",
        "82       favorite  0.0016  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  -0.0270734866002\n",
        "AUC:  0.514883782061\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective    coef   p-value\n",
        "120  inexpensive  0.1140  0.000000\n",
        "93          full  0.0438  0.000000\n",
        "14         baked  0.0327  0.000000\n",
        "83           few  0.0294  0.000000\n",
        "56          dish  0.0091  0.000000\n",
        "35       chinese -0.0829  0.002318\n",
        "179        quick -0.0168  0.004851\n",
        "154         next  0.0210  0.006621\n",
        "130        large -0.0158  0.006621\n",
        "114     horrible -0.0324  0.006621\n",
        "124          ive -0.0264  0.009112\n",
        "113         high  0.0792  0.012537\n",
        "118   incredible  0.0127  0.012537\n",
        "68      eggplant -0.0432  0.012537\n",
        "146     mediocre -0.1384  0.012537\n",
        "149         much  0.0396  0.014883\n",
        "199        short  0.1068  0.015660\n",
        "47         crazy  0.0316  0.015660\n",
        "25          busy -0.0378  0.015660\n",
        "104       greasy -0.0779  0.015660\n",
        "10     available -0.0937  0.015660\n",
        "133        later -0.1298  0.015660\n",
        "163        other -0.0005  0.020173\n",
        "116         huge -0.0639  0.025169\n",
        "254        yummy  0.0469  0.040728\n",
        "23        bubble  0.0391  0.045608\n",
        "5     affordable  0.0061  0.045608\n",
        "54     different -0.0040  0.045608\n",
        "131         last -0.0163  0.045608\n",
        "51        decent  0.0553  0.049499\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0153673116839\n",
        "AUC:  0.616453415498\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective    coef   p-value\n",
        "230        tiny -0.0225  0.000085\n",
        "3     addictive  0.0950  0.000490\n",
        "151     natural  0.0361  0.000490\n",
        "228    terrific  0.0222  0.000981\n",
        "238      unique -0.0312  0.000981\n",
        "169    personal -0.0176  0.002052\n",
        "54    different -0.0040  0.002205\n",
        "163       other -0.0005  0.002261\n",
        "90        fresh  0.0131  0.002581\n",
        "13          bad -0.0062  0.003905\n",
        "66          eat -0.0031  0.007615\n",
        "224       swiss  0.0856  0.007943\n",
        "29       casual -0.0786  0.007943\n",
        "9     authentic  0.0092  0.008253\n",
        "180       quiet  0.0412  0.009322\n",
        "5    affordable  0.0061  0.009322\n",
        "40        close -0.0286  0.009322\n",
        "58         dont  0.0163  0.009461\n",
        "182        real  0.0094  0.010006\n",
        "95       garlic -0.0077  0.010360\n",
        "1        accept  0.0405  0.010862\n",
        "30      central  0.0343  0.010862\n",
        "56         dish  0.0091  0.011253\n",
        "191         sad  0.0085  0.015087\n",
        "140       magic -0.0354  0.015087\n",
        "204        slow -0.0116  0.016624\n",
        "157         old -0.0030  0.018804\n",
        "79    fantastic -0.0188  0.020690\n",
        "38        clean  0.0037  0.023304\n",
        "202      simple  0.0226  0.024510\n",
        "119      indian -0.0069  0.024510\n",
        "20        black  0.0394  0.029148\n",
        "57         dive -0.0270  0.030205\n",
        "143        many  0.0036  0.032713\n",
        "130       large -0.0158  0.036375\n",
        "251       youll -0.0307  0.036375\n",
        "26         cant  0.0110  0.037648\n",
        "118  incredible  0.0127  0.038944\n",
        "110     healthy  0.0384  0.039847\n",
        "209       solid  0.0167  0.039847\n",
        "45         cool  0.0238  0.043770\n",
        "234     turkish -0.0607  0.044770\n",
        "193    saltfish -0.0485  0.045706\n",
        "15        basic  0.1099  0.046227\n",
        "178      public  0.0145  0.046227\n",
        "210    spacious  0.0123  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic = linear_model.LogisticRegression()\n",
      "clf_logistic.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_logistic, X_train, y_train, X_adjs.columns, 'logistic')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_logistic, X_test, y_test, X_adjs.columns, 'logistic')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_logistic, X_adjs.values, y.values, X_adjs.columns, 'logistic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.901003593111\n",
        "AUC:  0.500625\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective      coef   p-value\n",
        "163         other  1.057386  0.000050\n",
        "26           cant  1.184831  0.000081\n",
        "73           epic  1.098779  0.000087\n",
        "250        yellow  1.097571  0.000087\n",
        "210      spacious  1.052954  0.000087\n",
        "87      flavorful  1.143622  0.000174\n",
        "5      affordable  1.044564  0.000261\n",
        "96        general  1.248696  0.001122\n",
        "209         solid  1.152807  0.001918\n",
        "122         irish  0.962232  0.003553\n",
        "215         steak  0.986887  0.004008\n",
        "95         garlic  0.938474  0.004226\n",
        "46           cozy  0.893776  0.006104\n",
        "115           hot  1.031176  0.006348\n",
        "227      terrible  1.015316  0.007124\n",
        "158         olive  1.137463  0.008315\n",
        "237  unbelievable  1.029219  0.008315\n",
        "38          clean  1.051376  0.008604\n",
        "138          long  0.981474  0.009899\n",
        "84          first  0.957337  0.011209\n",
        "56           dish  1.086107  0.013767\n",
        "151       natural  1.067479  0.014504\n",
        "191           sad  1.002704  0.014504\n",
        "216       stellar  0.941576  0.014504\n",
        "140         magic  0.860020  0.014504\n",
        "119        indian  0.969282  0.020247\n",
        "157           old  0.971514  0.020831\n",
        "223         sweet  1.015316  0.023556\n",
        "118    incredible  1.085239  0.025013\n",
        "228      terrific  1.048332  0.029040\n",
        "169      personal  0.903481  0.029040\n",
        "170    phenomenal  0.886300  0.029040\n",
        "107       grilled  1.022244  0.031371\n",
        "239         usual  1.144651  0.033534\n",
        "81            fat  1.101199  0.033534\n",
        "162      original  1.086650  0.033534\n",
        "127           kid  1.086107  0.033534\n",
        "178        public  1.072186  0.033534\n",
        "54      different  0.943933  0.033618\n",
        "82       favorite  1.031589  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.888888888889\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "120  inexpensive  2.360091  0.000000\n",
        "93          full  1.620282  0.000000\n",
        "83           few  1.384307  0.000000\n",
        "14         baked  1.355134  0.000000\n",
        "56          dish  1.086107  0.000000\n",
        "35       chinese  0.505807  0.002318\n",
        "179        quick  0.853679  0.004851\n",
        "154         next  1.204061  0.006621\n",
        "130        large  0.860708  0.006621\n",
        "114     horrible  0.753294  0.006621\n",
        "124          ive  0.785920  0.009112\n",
        "113         high  2.387866  0.012537\n",
        "118   incredible  1.085239  0.012537\n",
        "68      eggplant  0.727894  0.012537\n",
        "146     mediocre  0.431538  0.012537\n",
        "149         much  1.625800  0.014883\n",
        "199        short  2.895622  0.015660\n",
        "47         crazy  1.344874  0.015660\n",
        "25          busy  0.810098  0.015660\n",
        "104       greasy  0.628449  0.015660\n",
        "10     available  0.507987  0.015660\n",
        "133        later  0.476589  0.015660\n",
        "163        other  1.057386  0.020173\n",
        "116         huge  0.606652  0.025169\n",
        "254        yummy  1.751548  0.040728\n",
        "23        bubble  1.441234  0.045608\n",
        "5     affordable  1.044564  0.045608\n",
        "54     different  0.943933  0.045608\n",
        "131         last  0.852740  0.045608\n",
        "51        decent  1.715321  0.049499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.897974354209\n",
        "AUC:  0.500454959054\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "230        tiny  0.858216  0.000085\n",
        "3     addictive  1.555816  0.000490\n",
        "151     natural  1.067479  0.000490\n",
        "228    terrific  1.048332  0.000981\n",
        "238      unique  0.815136  0.000981\n",
        "169    personal  0.903481  0.002052\n",
        "54    different  0.943933  0.002205\n",
        "163       other  1.057386  0.002261\n",
        "90        fresh  1.188509  0.002581\n",
        "13          bad  0.933607  0.003905\n",
        "66          eat  0.951800  0.007615\n",
        "224       swiss  1.352156  0.007943\n",
        "29       casual  0.736460  0.007943\n",
        "9     authentic  1.049171  0.008253\n",
        "180       quiet  1.439218  0.009322\n",
        "5    affordable  1.044564  0.009322\n",
        "40        close  0.794613  0.009322\n",
        "58         dont  1.234542  0.009461\n",
        "182        real  1.113268  0.010006\n",
        "95       garlic  0.938474  0.010360\n",
        "1        accept  1.302128  0.010862\n",
        "30      central  1.269979  0.010862\n",
        "56         dish  1.086107  0.011253\n",
        "191         sad  1.002704  0.015087\n",
        "140       magic  0.860020  0.015087\n",
        "204        slow  0.896999  0.016624\n",
        "157         old  0.971514  0.018804\n",
        "79    fantastic  0.846623  0.020690\n",
        "38        clean  1.051376  0.023304\n",
        "202      simple  1.174568  0.024510\n",
        "119      indian  0.969282  0.024510\n",
        "20        black  1.402000  0.029148\n",
        "57         dive  0.859590  0.030205\n",
        "143        many  1.043938  0.032713\n",
        "130       large  0.860708  0.036375\n",
        "251       youll  0.745575  0.036375\n",
        "26         cant  1.184831  0.037648\n",
        "118  incredible  1.085239  0.038944\n",
        "110     healthy  1.474177  0.039847\n",
        "209       solid  1.152807  0.039847\n",
        "45         cool  1.258222  0.043770\n",
        "234     turkish  0.737713  0.044770\n",
        "193    saltfish  0.823576  0.045706\n",
        "15        basic  1.494662  0.046227\n",
        "178      public  1.072186  0.046227\n",
        "210    spacious  1.052954  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predicting Grade \"C\" restaurants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tips_adj_df['grade_C']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X_adjs, y, random_state=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_multi_nb = naive_bayes.MultinomialNB()\n",
      "clf_multi_nb = clf_multi_nb.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_multi_nb, X_train, y_train, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_multi_nb, X_test, y_test, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_multi_nb, X_adjs.values, y.values, X_adjs.columns, 'naive-bayes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.901251393879\n",
        "AUC:  0.502431233668\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective      coef   p-value\n",
        "163         other  0.005634  0.000050\n",
        "26           cant  0.009299  0.000081\n",
        "73           epic  0.000679  0.000087\n",
        "210      spacious  0.000679  0.000087\n",
        "250        yellow  0.000679  0.000087\n",
        "87      flavorful  0.001290  0.000174\n",
        "5      affordable  0.001901  0.000261\n",
        "96        general  0.002579  0.001122\n",
        "209         solid  0.001968  0.001918\n",
        "122         irish  0.001358  0.003553\n",
        "215         steak  0.006109  0.004008\n",
        "95         garlic  0.004277  0.004226\n",
        "46           cozy  0.001833  0.006104\n",
        "115           hot  0.012015  0.006348\n",
        "227      terrible  0.002647  0.007124\n",
        "158         olive  0.000747  0.008315\n",
        "237  unbelievable  0.000747  0.008315\n",
        "38          clean  0.004548  0.008604\n",
        "138          long  0.005430  0.009899\n",
        "84          first  0.004209  0.011209\n",
        "56           dish  0.002987  0.013767\n",
        "140         magic  0.000611  0.014504\n",
        "151       natural  0.000611  0.014504\n",
        "191           sad  0.000611  0.014504\n",
        "216       stellar  0.000611  0.014504\n",
        "119        indian  0.001765  0.020247\n",
        "157           old  0.004005  0.020831\n",
        "223         sweet  0.007738  0.023556\n",
        "118    incredible  0.002104  0.025013\n",
        "169      personal  0.001154  0.029040\n",
        "170    phenomenal  0.001154  0.029040\n",
        "228      terrific  0.001154  0.029040\n",
        "107       grilled  0.005974  0.031371\n",
        "81            fat  0.000815  0.033534\n",
        "127           kid  0.000815  0.033534\n",
        "162      original  0.000815  0.033534\n",
        "178        public  0.000815  0.033534\n",
        "239         usual  0.000815  0.033534\n",
        "54      different  0.002308  0.033618\n",
        "82       favorite  0.006652  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.888888888889\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "83           few  0.003665  0.000000\n",
        "56          dish  0.002987  0.000000\n",
        "14         baked  0.002715  0.000000\n",
        "93          full  0.002579  0.000000\n",
        "120  inexpensive  0.001290  0.000000\n",
        "35       chinese  0.006517  0.002318\n",
        "179        quick  0.003462  0.004851\n",
        "130        large  0.003937  0.006621\n",
        "114     horrible  0.003326  0.006621\n",
        "154         next  0.003326  0.006621\n",
        "124          ive  0.008349  0.009112\n",
        "113         high  0.002715  0.012537\n",
        "118   incredible  0.002104  0.012537\n",
        "68      eggplant  0.001833  0.012537\n",
        "146     mediocre  0.001222  0.012537\n",
        "149         much  0.008077  0.014883\n",
        "10     available  0.002104  0.015660\n",
        "47         crazy  0.001968  0.015660\n",
        "199        short  0.001901  0.015660\n",
        "25          busy  0.001629  0.015660\n",
        "104       greasy  0.001154  0.015660\n",
        "133        later  0.001154  0.015660\n",
        "163        other  0.005634  0.020173\n",
        "116         huge  0.004141  0.025169\n",
        "254        yummy  0.006992  0.040728\n",
        "131         last  0.002579  0.045608\n",
        "54     different  0.002308  0.045608\n",
        "23        bubble  0.002240  0.045608\n",
        "5     affordable  0.001901  0.045608\n",
        "51        decent  0.005023  0.049499\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.898160193273\n",
        "AUC:  0.50176809245\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "230        tiny  0.001968  0.000085\n",
        "151     natural  0.000611  0.000490\n",
        "3     addictive  0.000543  0.000490\n",
        "228    terrific  0.001154  0.000981\n",
        "238      unique  0.001086  0.000981\n",
        "169    personal  0.001154  0.002052\n",
        "54    different  0.002308  0.002205\n",
        "163       other  0.005634  0.002261\n",
        "90        fresh  0.014595  0.002581\n",
        "13          bad  0.008077  0.003905\n",
        "66          eat  0.009299  0.007615\n",
        "29       casual  0.000407  0.007943\n",
        "224       swiss  0.000407  0.007943\n",
        "9     authentic  0.003190  0.008253\n",
        "180       quiet  0.001968  0.009322\n",
        "5    affordable  0.001901  0.009322\n",
        "40        close  0.001901  0.009322\n",
        "58         dont  0.025929  0.009461\n",
        "182        real  0.003734  0.010006\n",
        "95       garlic  0.004277  0.010360\n",
        "1        accept  0.001154  0.010862\n",
        "30      central  0.001154  0.010862\n",
        "56         dish  0.002987  0.011253\n",
        "140       magic  0.000611  0.015087\n",
        "191         sad  0.000611  0.015087\n",
        "204        slow  0.007195  0.016624\n",
        "157         old  0.004005  0.018804\n",
        "79    fantastic  0.004887  0.020690\n",
        "38        clean  0.004548  0.023304\n",
        "119      indian  0.001765  0.024510\n",
        "202      simple  0.001697  0.024510\n",
        "20        black  0.002851  0.029148\n",
        "57         dive  0.001018  0.030205\n",
        "143        many  0.003055  0.032713\n",
        "130       large  0.003937  0.036375\n",
        "251       youll  0.003937  0.036375\n",
        "26         cant  0.009299  0.037648\n",
        "118  incredible  0.002104  0.038944\n",
        "110     healthy  0.002308  0.039847\n",
        "209       solid  0.001968  0.039847\n",
        "45         cool  0.004277  0.043770\n",
        "234     turkish  0.000815  0.044770\n",
        "193    saltfish  0.000475  0.045706\n",
        "178      public  0.000815  0.046227\n",
        "210    spacious  0.000679  0.046227\n",
        "15        basic  0.000475  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_linear = linear_model.LinearRegression()\n",
      "clf_linear = clf_linear.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_linear, X_train, y_train, X_adjs.columns, 'linear')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_linear, X_test, y_test, X_adjs.columns, 'linear')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_linear, X_adjs.values, y.values, X_adjs.columns, 'linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0306220058522\n",
        "AUC:  0.65453453789\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective    coef   p-value\n",
        "163         other -0.0005  0.000050\n",
        "26           cant  0.0110  0.000081\n",
        "73           epic  0.0196  0.000087\n",
        "250        yellow  0.0143  0.000087\n",
        "210      spacious  0.0123  0.000087\n",
        "87      flavorful  0.0218  0.000174\n",
        "5      affordable  0.0061  0.000261\n",
        "96        general  0.0292  0.001122\n",
        "209         solid  0.0167  0.001918\n",
        "122         irish -0.0082  0.003553\n",
        "215         steak -0.0008  0.004008\n",
        "95         garlic -0.0077  0.004226\n",
        "46           cozy -0.0200  0.006104\n",
        "115           hot  0.0042  0.006348\n",
        "227      terrible -0.0021  0.007124\n",
        "158         olive  0.0464  0.008315\n",
        "237  unbelievable  0.0079  0.008315\n",
        "38          clean  0.0037  0.008604\n",
        "138          long -0.0036  0.009899\n",
        "84          first -0.0020  0.011209\n",
        "56           dish  0.0091  0.013767\n",
        "151       natural  0.0361  0.014504\n",
        "191           sad  0.0085  0.014504\n",
        "216       stellar -0.0123  0.014504\n",
        "140         magic -0.0354  0.014504\n",
        "119        indian -0.0069  0.020247\n",
        "157           old -0.0030  0.020831\n",
        "223         sweet  0.0028  0.023556\n",
        "118    incredible  0.0127  0.025013\n",
        "228      terrific  0.0222  0.029040\n",
        "169      personal -0.0176  0.029040\n",
        "170    phenomenal -0.0186  0.029040\n",
        "107       grilled  0.0041  0.031371\n",
        "239         usual  0.0336  0.033534\n",
        "127           kid  0.0176  0.033534\n",
        "162      original  0.0168  0.033534\n",
        "81            fat  0.0163  0.033534\n",
        "178        public  0.0145  0.033534\n",
        "54      different -0.0040  0.033618\n",
        "82       favorite  0.0016  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  -0.0270734866002\n",
        "AUC:  0.514883782061\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective    coef   p-value\n",
        "120  inexpensive  0.1140  0.000000\n",
        "93          full  0.0438  0.000000\n",
        "14         baked  0.0327  0.000000\n",
        "83           few  0.0294  0.000000\n",
        "56          dish  0.0091  0.000000\n",
        "35       chinese -0.0829  0.002318\n",
        "179        quick -0.0168  0.004851\n",
        "154         next  0.0210  0.006621\n",
        "130        large -0.0158  0.006621\n",
        "114     horrible -0.0324  0.006621\n",
        "124          ive -0.0264  0.009112\n",
        "113         high  0.0792  0.012537\n",
        "118   incredible  0.0127  0.012537\n",
        "68      eggplant -0.0432  0.012537\n",
        "146     mediocre -0.1384  0.012537\n",
        "149         much  0.0396  0.014883\n",
        "199        short  0.1068  0.015660\n",
        "47         crazy  0.0316  0.015660\n",
        "25          busy -0.0378  0.015660\n",
        "104       greasy -0.0779  0.015660\n",
        "10     available -0.0937  0.015660\n",
        "133        later -0.1298  0.015660\n",
        "163        other -0.0005  0.020173\n",
        "116         huge -0.0639  0.025169\n",
        "254        yummy  0.0469  0.040728\n",
        "23        bubble  0.0391  0.045608\n",
        "5     affordable  0.0061  0.045608\n",
        "54     different -0.0040  0.045608\n",
        "131         last -0.0163  0.045608\n",
        "51        decent  0.0553  0.049499\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
        "SCORE:  0.0153673116839\n",
        "AUC:  0.616453415498\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective    coef   p-value\n",
        "230        tiny -0.0225  0.000085\n",
        "3     addictive  0.0950  0.000490\n",
        "151     natural  0.0361  0.000490\n",
        "228    terrific  0.0222  0.000981\n",
        "238      unique -0.0312  0.000981\n",
        "169    personal -0.0176  0.002052\n",
        "54    different -0.0040  0.002205\n",
        "163       other -0.0005  0.002261\n",
        "90        fresh  0.0131  0.002581\n",
        "13          bad -0.0062  0.003905\n",
        "66          eat -0.0031  0.007615\n",
        "224       swiss  0.0856  0.007943\n",
        "29       casual -0.0786  0.007943\n",
        "9     authentic  0.0092  0.008253\n",
        "180       quiet  0.0412  0.009322\n",
        "5    affordable  0.0061  0.009322\n",
        "40        close -0.0286  0.009322\n",
        "58         dont  0.0163  0.009461\n",
        "182        real  0.0094  0.010006\n",
        "95       garlic -0.0077  0.010360\n",
        "1        accept  0.0405  0.010862\n",
        "30      central  0.0343  0.010862\n",
        "56         dish  0.0091  0.011253\n",
        "191         sad  0.0085  0.015087\n",
        "140       magic -0.0354  0.015087\n",
        "204        slow -0.0116  0.016624\n",
        "157         old -0.0030  0.018804\n",
        "79    fantastic -0.0188  0.020690\n",
        "38        clean  0.0037  0.023304\n",
        "202      simple  0.0226  0.024510\n",
        "119      indian -0.0069  0.024510\n",
        "20        black  0.0394  0.029148\n",
        "57         dive -0.0270  0.030205\n",
        "143        many  0.0036  0.032713\n",
        "130       large -0.0158  0.036375\n",
        "251       youll -0.0307  0.036375\n",
        "26         cant  0.0110  0.037648\n",
        "118  incredible  0.0127  0.038944\n",
        "110     healthy  0.0384  0.039847\n",
        "209       solid  0.0167  0.039847\n",
        "45         cool  0.0238  0.043770\n",
        "234     turkish -0.0607  0.044770\n",
        "193    saltfish -0.0485  0.045706\n",
        "15        basic  0.1099  0.046227\n",
        "178      public  0.0145  0.046227\n",
        "210    spacious  0.0123  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic = linear_model.LogisticRegression()\n",
      "clf_logistic = clf_logistic.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_logistic, X_train, y_train, X_adjs.columns, 'logistic')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_logistic, X_test, y_test, X_adjs.columns, 'logistic')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_logistic, X_adjs.values, y.values, X_adjs.columns, 'logistic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.901003593111\n",
        "AUC:  0.500625\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "        adjective      coef   p-value\n",
        "163         other  1.057386  0.000050\n",
        "26           cant  1.184831  0.000081\n",
        "73           epic  1.098779  0.000087\n",
        "250        yellow  1.097571  0.000087\n",
        "210      spacious  1.052954  0.000087\n",
        "87      flavorful  1.143622  0.000174\n",
        "5      affordable  1.044564  0.000261\n",
        "96        general  1.248696  0.001122\n",
        "209         solid  1.152807  0.001918\n",
        "122         irish  0.962232  0.003553\n",
        "215         steak  0.986887  0.004008\n",
        "95         garlic  0.938474  0.004226\n",
        "46           cozy  0.893776  0.006104\n",
        "115           hot  1.031176  0.006348\n",
        "227      terrible  1.015316  0.007124\n",
        "158         olive  1.137463  0.008315\n",
        "237  unbelievable  1.029219  0.008315\n",
        "38          clean  1.051376  0.008604\n",
        "138          long  0.981474  0.009899\n",
        "84          first  0.957337  0.011209\n",
        "56           dish  1.086107  0.013767\n",
        "151       natural  1.067479  0.014504\n",
        "191           sad  1.002704  0.014504\n",
        "216       stellar  0.941576  0.014504\n",
        "140         magic  0.860020  0.014504\n",
        "119        indian  0.969282  0.020247\n",
        "157           old  0.971514  0.020831\n",
        "223         sweet  1.015316  0.023556\n",
        "118    incredible  1.085239  0.025013\n",
        "228      terrific  1.048332  0.029040\n",
        "169      personal  0.903481  0.029040\n",
        "170    phenomenal  0.886300  0.029040\n",
        "107       grilled  1.022244  0.031371\n",
        "239         usual  1.144651  0.033534\n",
        "81            fat  1.101199  0.033534\n",
        "162      original  1.086650  0.033534\n",
        "127           kid  1.086107  0.033534\n",
        "178        public  1.072186  0.033534\n",
        "54      different  0.943933  0.033618\n",
        "82       favorite  1.031589  0.038926\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.888888888889\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "120  inexpensive  2.360091  0.000000\n",
        "93          full  1.620282  0.000000\n",
        "83           few  1.384307  0.000000\n",
        "14         baked  1.355134  0.000000\n",
        "56          dish  1.086107  0.000000\n",
        "35       chinese  0.505807  0.002318\n",
        "179        quick  0.853679  0.004851\n",
        "154         next  1.204061  0.006621\n",
        "130        large  0.860708  0.006621\n",
        "114     horrible  0.753294  0.006621\n",
        "124          ive  0.785920  0.009112\n",
        "113         high  2.387866  0.012537\n",
        "118   incredible  1.085239  0.012537\n",
        "68      eggplant  0.727894  0.012537\n",
        "146     mediocre  0.431538  0.012537\n",
        "149         much  1.625800  0.014883\n",
        "199        short  2.895622  0.015660\n",
        "47         crazy  1.344874  0.015660\n",
        "25          busy  0.810098  0.015660\n",
        "104       greasy  0.628449  0.015660\n",
        "10     available  0.507987  0.015660\n",
        "133        later  0.476589  0.015660\n",
        "163        other  1.057386  0.020173\n",
        "116         huge  0.606652  0.025169\n",
        "254        yummy  1.751548  0.040728\n",
        "23        bubble  1.441234  0.045608\n",
        "5     affordable  1.044564  0.045608\n",
        "54     different  0.943933  0.045608\n",
        "131         last  0.852740  0.045608\n",
        "51        decent  1.715321  0.049499\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "SCORE:  0.897974354209\n",
        "AUC:  0.500454959054\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "230        tiny  0.858216  0.000085\n",
        "3     addictive  1.555816  0.000490\n",
        "151     natural  1.067479  0.000490\n",
        "228    terrific  1.048332  0.000981\n",
        "238      unique  0.815136  0.000981\n",
        "169    personal  0.903481  0.002052\n",
        "54    different  0.943933  0.002205\n",
        "163       other  1.057386  0.002261\n",
        "90        fresh  1.188509  0.002581\n",
        "13          bad  0.933607  0.003905\n",
        "66          eat  0.951800  0.007615\n",
        "224       swiss  1.352156  0.007943\n",
        "29       casual  0.736460  0.007943\n",
        "9     authentic  1.049171  0.008253\n",
        "180       quiet  1.439218  0.009322\n",
        "5    affordable  1.044564  0.009322\n",
        "40        close  0.794613  0.009322\n",
        "58         dont  1.234542  0.009461\n",
        "182        real  1.113268  0.010006\n",
        "95       garlic  0.938474  0.010360\n",
        "1        accept  1.302128  0.010862\n",
        "30      central  1.269979  0.010862\n",
        "56         dish  1.086107  0.011253\n",
        "191         sad  1.002704  0.015087\n",
        "140       magic  0.860020  0.015087\n",
        "204        slow  0.896999  0.016624\n",
        "157         old  0.971514  0.018804\n",
        "79    fantastic  0.846623  0.020690\n",
        "38        clean  1.051376  0.023304\n",
        "202      simple  1.174568  0.024510\n",
        "119      indian  0.969282  0.024510\n",
        "20        black  1.402000  0.029148\n",
        "57         dive  0.859590  0.030205\n",
        "143        many  1.043938  0.032713\n",
        "130       large  0.860708  0.036375\n",
        "251       youll  0.745575  0.036375\n",
        "26         cant  1.184831  0.037648\n",
        "118  incredible  1.085239  0.038944\n",
        "110     healthy  1.474177  0.039847\n",
        "209       solid  1.152807  0.039847\n",
        "45         cool  1.258222  0.043770\n",
        "234     turkish  0.737713  0.044770\n",
        "193    saltfish  0.823576  0.045706\n",
        "15        basic  1.494662  0.046227\n",
        "178      public  1.072186  0.046227\n",
        "210    spacious  1.052954  0.046227\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5)\n",
      "\n",
      "print 'Using training set'\n",
      "clf_tree = clf_tree.fit(X_train, y_train)\n",
      "score = clf_tree.score(X_train, y_train)\n",
      "y_pred = clf_tree.predict(X_train)\n",
      "\n",
      "print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y_train, y_pred)), \"\\n\"\n",
      "print \"Classification report\"\n",
      "print metrics.classification_report(y_train, y_pred), \"\\n\"\n",
      "        \n",
      "print \"Confusion matrix\"\n",
      "print metrics.confusion_matrix(y_train, y_pred), \"\\n\"\n",
      "\n",
      "print 'Using testing set'\n",
      "score = clf_tree.score(X_test, y_test)\n",
      "y_pred = clf_tree.predict(X_test)\n",
      "\n",
      "print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred)), \"\\n\"\n",
      "print \"Classification report\"\n",
      "print metrics.classification_report(y_test, y_pred), \"\\n\"\n",
      "        \n",
      "print \"Confusion matrix\"\n",
      "print metrics.confusion_matrix(y_test, y_pred), \"\\n\"\n",
      "\n",
      "print 'Using all data'\n",
      "score = clf_tree.score(X_adjs.values, y.values)\n",
      "y_pred = clf_tree.predict(X_adjs.values)\n",
      "\n",
      "print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y.values, y_pred)), \"\\n\"\n",
      "print \"Classification report\"\n",
      "print metrics.classification_report(y.values, y_pred), \"\\n\"\n",
      "        \n",
      "print \"Confusion matrix\"\n",
      "print metrics.confusion_matrix(y.values, y_pred), \"\\n\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "Accuracy:0.901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.50      0.00      0.01       800\n",
        "        1.0       0.90      1.00      0.95      7271\n",
        "\n",
        "avg / total       0.86      0.90      0.85      8071\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[   3  797]\n",
        " [   3 7268]] \n",
        "\n",
        "Using testing set\n",
        "Accuracy:0.888 \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.00      0.00      0.00       299\n",
        "        1.0       0.89      1.00      0.94      2392\n",
        "\n",
        "avg / total       0.79      0.89      0.84      2691\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[   0  299]\n",
        " [   2 2390]] \n",
        "\n",
        "Using all data\n",
        "Accuracy:0.898"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.38      0.00      0.01      1099\n",
        "        1.0       0.90      1.00      0.95      9663\n",
        "\n",
        "avg / total       0.84      0.90      0.85     10762\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[   3 1096]\n",
        " [   5 9658]] \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tips_adj_df[tips_adj_df['foursquare_price_tier'] == 1]['grade_C']\n",
      "cheap_df = tips_adj_df[tips_adj_df['foursquare_price_tier'] == 1]\n",
      "X_adjs = cheap_df.ix[:, 34:-1]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X_adjs, y, random_state=8)\n",
      "\n",
      "clf_multi_nb = naive_bayes.MultinomialNB()\n",
      "clf_multi_nb.fit(X_train, y_train)\n",
      "\n",
      "print 'Using training set'\n",
      "score_and_predict(clf_multi_nb, X_train, y_train, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using testing set'\n",
      "score_and_predict(clf_multi_nb, X_test, y_test, X_adjs.columns, 'naive-bayes')\n",
      "\n",
      "print 'Using all data'\n",
      "score_and_predict(clf_multi_nb, X_adjs.values, y.values, X_adjs.columns, 'naive-bayes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using training set\n",
        "MODEL:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.990886998785\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "10     available  0.003484  0.009191\n",
        "11       average  0.003484  0.009191\n",
        "24         bushy  0.003484  0.009191\n",
        "31       certain  0.003484  0.009191\n",
        "67     efficient  0.003484  0.009191\n",
        "73          epic  0.003484  0.009191\n",
        "86          flat  0.003484  0.009191\n",
        "111        heavy  0.003484  0.009191\n",
        "126          key  0.003484  0.009191\n",
        "148       modern  0.003484  0.009191\n",
        "151      natural  0.003484  0.009191\n",
        "161      organic  0.003484  0.009191\n",
        "171          pic  0.003484  0.009191\n",
        "172     pleasant  0.003484  0.009191\n",
        "186   ridiculous  0.003484  0.009191\n",
        "190      russian  0.003484  0.009191\n",
        "193     saltfish  0.003484  0.009191\n",
        "200     sicilian  0.003484  0.009191\n",
        "201      similar  0.003484  0.009191\n",
        "203        sized  0.003484  0.009191\n",
        "216      stellar  0.003484  0.009191\n",
        "234      turkish  0.003484  0.009191\n",
        "236   unbeatable  0.003484  0.009191\n",
        "238       unique  0.003484  0.009191\n",
        "5     affordable  0.003484  0.018394\n",
        "7          asian  0.003484  0.018394\n",
        "8      attentive  0.003484  0.018394\n",
        "15         basic  0.003484  0.018394\n",
        "30       central  0.003484  0.018394\n",
        "48      creative  0.003484  0.018394\n",
        "..           ...       ...       ...\n",
        "224        swiss  0.003484  0.027608\n",
        "230         tiny  0.003484  0.027608\n",
        "233         true  0.003484  0.027608\n",
        "252        young  0.003484  0.027608\n",
        "102         good  0.010453  0.028718\n",
        "12         awful  0.003484  0.036833\n",
        "18     beautiful  0.003484  0.036833\n",
        "47         crazy  0.003484  0.036833\n",
        "57          dive  0.003484  0.036833\n",
        "72        entire  0.003484  0.036833\n",
        "101         goat  0.003484  0.036833\n",
        "104       greasy  0.003484  0.036833\n",
        "113         high  0.003484  0.036833\n",
        "158        olive  0.003484  0.036833\n",
        "165      overall  0.003484  0.036833\n",
        "166          own  0.003484  0.036833\n",
        "202       simple  0.003484  0.036833\n",
        "211      spanish  0.003484  0.036833\n",
        "217     straight  0.003484  0.036833\n",
        "219         such  0.003484  0.036833\n",
        "232  traditional  0.003484  0.036833\n",
        "16          bean  0.003484  0.046069\n",
        "40         close  0.003484  0.046069\n",
        "55         dirty  0.003484  0.046069\n",
        "65          easy  0.003484  0.046069\n",
        "81           fat  0.003484  0.046069\n",
        "87     flavorful  0.003484  0.046069\n",
        "183   reasonable  0.003484  0.046069\n",
        "235      typical  0.003484  0.046069\n",
        "244        weird  0.003484  0.046069\n",
        "\n",
        "[116 rows x 3 columns]\n",
        "\n",
        "\n",
        "Using testing set\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.992714025501\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "      adjective      coef   p-value\n",
        "75    expensive  0.006969  0.007326\n",
        "77     fabulous  0.006969  0.007326\n",
        "3     addictive  0.003484  0.007326\n",
        "5    affordable  0.003484  0.007326\n",
        "6      american  0.003484  0.007326\n",
        "7         asian  0.003484  0.007326\n",
        "8     attentive  0.003484  0.007326\n",
        "10    available  0.003484  0.007326\n",
        "11      average  0.003484  0.007326\n",
        "14        baked  0.003484  0.007326\n",
        "23       bubble  0.003484  0.007326\n",
        "29       casual  0.003484  0.007326\n",
        "31      certain  0.003484  0.007326\n",
        "46         cozy  0.003484  0.007326\n",
        "55        dirty  0.003484  0.007326\n",
        "56         dish  0.003484  0.007326\n",
        "61          dry  0.003484  0.007326\n",
        "65         easy  0.003484  0.007326\n",
        "68     eggplant  0.003484  0.007326\n",
        "69        empty  0.003484  0.007326\n",
        "73         epic  0.003484  0.007326\n",
        "86         flat  0.003484  0.007326\n",
        "87    flavorful  0.003484  0.007326\n",
        "89       french  0.003484  0.007326\n",
        "93         full  0.003484  0.007326\n",
        "94        funny  0.003484  0.007326\n",
        "97     generous  0.003484  0.007326\n",
        "99    ginormous  0.003484  0.007326\n",
        "101        goat  0.003484  0.007326\n",
        "112     helpful  0.003484  0.007326\n",
        "..          ...       ...       ...\n",
        "106       green  0.003484  0.029467\n",
        "132        late  0.003484  0.029467\n",
        "152      nearby  0.003484  0.029467\n",
        "157         old  0.003484  0.029467\n",
        "181       ready  0.003484  0.029467\n",
        "184         red  0.003484  0.029467\n",
        "83          few  0.006969  0.036902\n",
        "242        want  0.006969  0.036902\n",
        "12        awful  0.003484  0.036902\n",
        "20        black  0.003484  0.036902\n",
        "25         busy  0.003484  0.036902\n",
        "49         cute  0.003484  0.036902\n",
        "51       decent  0.003484  0.036902\n",
        "53       delish  0.003484  0.036902\n",
        "85         fish  0.003484  0.036902\n",
        "96      general  0.003484  0.036902\n",
        "182        real  0.003484  0.036902\n",
        "215       steak  0.003484  0.036902\n",
        "13          bad  0.006969  0.044365\n",
        "38        clean  0.003484  0.044365\n",
        "74    excellent  0.003484  0.044365\n",
        "80         fast  0.003484  0.044365\n",
        "100        give  0.003484  0.044365\n",
        "108       happy  0.003484  0.044365\n",
        "116        huge  0.003484  0.044365\n",
        "168     perfect  0.003484  0.044365\n",
        "185     regular  0.003484  0.044365\n",
        "205       small  0.003484  0.044365\n",
        "209       solid  0.003484  0.044365\n",
        "251       youll  0.003484  0.044365\n",
        "\n",
        "[144 rows x 3 columns]\n",
        "\n",
        "\n",
        "Using all data\n",
        "MODEL: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "SCORE:  0.991343963554\n",
        "AUC:  0.5\n",
        "\n",
        "\n",
        "TOP PREDICTORS (p-value < 0.05):\n",
        "       adjective      coef   p-value\n",
        "3      addictive  0.003484  0.008728\n",
        "24         bushy  0.003484  0.008728\n",
        "29        casual  0.003484  0.008728\n",
        "67     efficient  0.003484  0.008728\n",
        "99     ginormous  0.003484  0.008728\n",
        "148       modern  0.003484  0.008728\n",
        "161      organic  0.003484  0.008728\n",
        "164  outstanding  0.003484  0.008728\n",
        "171          pic  0.003484  0.008728\n",
        "173       polish  0.003484  0.008728\n",
        "186   ridiculous  0.003484  0.008728\n",
        "187     rosemary  0.003484  0.008728\n",
        "190      russian  0.003484  0.008728\n",
        "193     saltfish  0.003484  0.008728\n",
        "200     sicilian  0.003484  0.008728\n",
        "203        sized  0.003484  0.008728\n",
        "214     standard  0.003484  0.008728\n",
        "216      stellar  0.003484  0.008728\n",
        "238       unique  0.003484  0.008728\n",
        "10     available  0.003484  0.017463\n",
        "11       average  0.003484  0.017463\n",
        "15         basic  0.003484  0.017463\n",
        "30       central  0.003484  0.017463\n",
        "31       certain  0.003484  0.017463\n",
        "48      creative  0.003484  0.017463\n",
        "73          epic  0.003484  0.017463\n",
        "78        famous  0.003484  0.017463\n",
        "86          flat  0.003484  0.017463\n",
        "121  interesting  0.003484  0.017463\n",
        "126          key  0.003484  0.017463\n",
        "..           ...       ...       ...\n",
        "72        entire  0.003484  0.034959\n",
        "94         funny  0.003484  0.034959\n",
        "97      generous  0.003484  0.034959\n",
        "119       indian  0.003484  0.034959\n",
        "120  inexpensive  0.003484  0.034959\n",
        "127          kid  0.003484  0.034959\n",
        "133        later  0.003484  0.034959\n",
        "139          low  0.003484  0.034959\n",
        "158        olive  0.003484  0.034959\n",
        "162     original  0.003484  0.034959\n",
        "178       public  0.003484  0.034959\n",
        "180        quiet  0.003484  0.034959\n",
        "211      spanish  0.003484  0.034959\n",
        "217     straight  0.003484  0.034959\n",
        "232  traditional  0.003484  0.034959\n",
        "243         weak  0.003484  0.034959\n",
        "252        young  0.003484  0.034959\n",
        "16          bean  0.003484  0.043719\n",
        "33        cheesy  0.003484  0.043719\n",
        "98         giant  0.003484  0.043719\n",
        "101         goat  0.003484  0.043719\n",
        "113         high  0.003484  0.043719\n",
        "118   incredible  0.003484  0.043719\n",
        "122        irish  0.003484  0.043719\n",
        "140        magic  0.003484  0.043719\n",
        "183   reasonable  0.003484  0.043719\n",
        "195       second  0.003484  0.043719\n",
        "202       simple  0.003484  0.043719\n",
        "206        smile  0.003484  0.043719\n",
        "218       strong  0.003484  0.043719\n",
        "\n",
        "[102 rows x 3 columns]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tips_adj_df.to_pickle('./dumps/tips_complete_features.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    }
   ],
   "metadata": {}
  }
 ]
}